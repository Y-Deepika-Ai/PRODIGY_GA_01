{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab7cbe95-140e-441b-a695-e8ef2e8268ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\saranya\\anaconda3\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\saranya\\anaconda3\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: torch in c:\\users\\saranya\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\saranya\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\saranya\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fbabcee-c92c-4222-a2d0-c6afc39af30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05913ad1b974b379fe5d614e9713e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARANYA\\AppData\\Local\\Temp\\ipykernel_6156\\3294954732.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARANYA\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 01:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a prompt (or type 'exit' to quit):  Artificial intelligence will change the way we interact with machines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Text:\n",
      " Artificial intelligence will change the way we interact with machines and our brains.\n",
      " 1) Machine learning could revolutionize how computers make decisions on behalf of humans 2)(iPad, iPad), 3). AI might enable a future that is far more accessible to people who are less constrained by technology's limitations (e-commerce giants like Amazon or Netflix in particular); it may also lead us towards smarter products for everyone; 4.) Machines learn from human actions through their own experiences rather than relying solely upon external systems which have learned its lessons over time 5). Artificial Intelligence can be used as an accelerator against existing problems – e.g., diseases such about Alzheimer's disease being solved using natural mechanisms [1]. In addition robots already play important roles within industries including medicine and health care due largely via robotic medical assistants provided they become better at recognizing certain stimuli faster/better knowing what others do while doing so 6–10). A shift away into computer science would help improve machine interactions between users across cultures all around the world 7). And finally there was this interesting fact: \"Humanity has gone extinct.\" This question made sense because if artificial intelligence were developed properly these tasks wouldn't necessarily require massive amounts omitting information unless those things included relevant resources 10.), but I guess when you're designing new devices your goal should always be not only finding ways to bring them back alive after death 11): We need greater control regarding where data comes out based both directly & indirectly 8a.). Furthermore automation makes every aspect modern everyday much easier 9b.). As soon software becomes ubiquitous then\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a prompt (or type 'exit' to quit):  Story of robots in robot land\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Text:\n",
      " Story of robots in robot land\n",
      "A new generation is rapidly developing a future where we can interact with machines to help us better understand our own behaviors, as well the world around them. This will be called robotics and it may turn out that humanity has already solved what's known about life on earth: how things work (or not) by building artificial intelligence hardware or software—the next step towards self-aware technology like AI for cars.\n",
      "\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a prompt (or type 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the program.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)\n",
    "\n",
    "texts = [\n",
    "    \"Once upon a time in a distant galaxy, there lived a wise old robot.\",\n",
    "    \"The jungle whispered secrets to the curious explorers.\",\n",
    "    \"Technology is reshaping the future faster than ever before.\",\n",
    "    \"The sky was filled with stars, each one telling a different story.\",\n",
    "    \"Artificial intelligence will change the way we interact with machines.\"\n",
    "]\n",
    "\n",
    "\n",
    "dataset = Dataset.from_dict({\"text\": texts})\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False\n",
    ")\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    prediction_loss_only=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Training the model...\")\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "model.save_pretrained(\"./gpt2-finetuned\")\n",
    "tokenizer.save_pretrained(\"./gpt2-finetuned\")\n",
    "print(\"Model training complete and saved!\")\n",
    "\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"./gpt2-finetuned\").to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2-finetuned\")\n",
    "\n",
    "\n",
    "def generate_text(prompt, max_new_tokens=300):  # Increase the token limit\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=max_new_tokens,  \n",
    "        do_sample=True,                \n",
    "        top_k=50,                       \n",
    "        top_p=0.95,                     \n",
    "        temperature=0.8,                \n",
    "        repetition_penalty=1.2,         \n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    prompt = input(\"Enter a prompt (or type 'exit' to quit): \")\n",
    "    if prompt.strip().lower() == 'exit':\n",
    "        print(\"Exiting the program.\")\n",
    "        break\n",
    "\n",
    "    # Generate text based on the user's prompt\n",
    "    generated_text = generate_text(prompt)\n",
    "    print(\"\\nGenerated Text:\\n\", generated_text)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ade62a-5326-4a56-adb3-1aff31f62081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
